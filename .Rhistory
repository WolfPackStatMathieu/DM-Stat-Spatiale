X=as.data.frame(X)
str(X)
colnames(X)=c('cos1', 'cos2','cos3', 'cos4', 'cos5',
'cos6', 'sin1', 'sin2', 'sin3', 'sin4',
'sin5')
reglin=lm(nottem ~ cos1 + sin1 + cos2 + sin2
+ cos3 + sin3 +cos4 + sin4 + cos5 + sin5
+cos6, data = X)
summary(reglin)
summary(reglin)
#4
reglin=lm(nottem ~ cos1 + sin1 + sin2 + sin4)
#4
reglin=lm(nottem ~ cos1 + sin1 + sin2 + sin4,
data = X)
summary(reglin)
reglin$fitted.values
ajust=reglin$fitted.values
resid=reglin$residuals
ts(resid, start=c(1920,1),
end=c(1939,12), frequency=12)
ajust=ts(ajust, start=c(1920,1),
end=c(1939,12), frequency=12)
#6
graph=cbind(nottem, ajust, resid)
plot.ts(graph)
d1=diff(nottem, lag = 12)
plot.ts(d1)
lines(resid, col='red')
plot.ts(d1)
lines(resid, col='red')
data("nottem")
summary(nottem)
head(nottem)
str(nottem)
plot.ts(nottem)
f=t(as.matrix(1:6))/12
temps=as.matrix(1:length(nottem))
X=cbind(cos(2*pi*temps %*%f), sin(2*pi*temps %*% f))[,-12]
X=as.data.frame(X)
colnames(X)=c('cos1', 'cos2','cos3', 'cos4', 'cos5',
'cos6', 'sin1', 'sin2', 'sin3', 'sin4',
'sin5')
reglin=lm(nottem ~ cos1 + sin1 + cos2 + sin2
+ cos3 + sin3 +cos4 + sin4 + cos5 + sin5
+cos6, data = X)
summary(reglin)
#4
reglin=lm(nottem ~ cos1 + sin1 + sin2 + sin4,
data = X)
summary(reglin)
#5
ajust=reglin$fitted.values
resid=reglin$residuals
resid=ts(resid, start=c(1920,1),
end=c(1939,12), frequency=12)
ajust=ts(ajust, start=c(1920,1),
end=c(1939,12), frequency=12)
#6
graph=cbind(nottem, ajust, resid)
plot.ts(graph)
#7 Filtrer la série de départ pour éliminer
# la saisonnalité en utilisant le filtre de
# différenciation saisonnière via la fonction
# diff. Superposer la série ainsi obtenue avec
# les résidus précédents. Commenter.
d1=diff(nottem, lag = 12)
plot.ts(d1)
lines(resid, col='red')
data("nottem")
summary(nottem)
head(nottem)
str(nottem)
plot.ts(nottem)
f=t(as.matrix(1:6))/12
temps=as.matrix(1:length(nottem))
X=cbind(cos(2*pi*temps %*%f), sin(2*pi*temps %*% f))[,-12]
X=as.data.frame(X)
colnames(X)=c('cos1', 'cos2','cos3', 'cos4', 'cos5',
'cos6', 'sin1', 'sin2', 'sin3', 'sin4',
'sin5')
reglin=lm(nottem ~ cos1 + sin1 + cos2 + sin2
+ cos3 + sin3 +cos4 + sin4 + cos5 + sin5
+cos6, data = X)
summary(reglin)
#4
reglin=lm(nottem ~ cos1 + sin1 + sin2 + sin4,
data = X)
summary(reglin)
#5
ajust=reglin$fitted.values
resid=reglin$residuals
resid=ts(resid, start=c(1920,1),
end=c(1939,12), frequency=12)
ajust=ts(ajust, start=c(1920,1),
end=c(1939,12), frequency=12)
#6
graph=cbind(nottem, ajust, resid)
plot.ts(graph)
#7 Filtrer la série de départ pour éliminer
# la saisonnalité en utilisant le filtre de
# différenciation saisonnière via la fonction
# diff. Superposer la série ainsi obtenue avec
# les résidus précédents. Commenter.
d1=diff(nottem, lag = 12)
plot.ts(d1)
lines(resid, col='red')
data("nottem")
summary(nottem)
head(nottem)
str(nottem)
plot.ts(nottem)
f=t(as.matrix(1:6))/12
temps=as.matrix(1:length(nottem))
X=cbind(cos(2*pi*temps %*%f), sin(2*pi*temps %*% f))[,-12]
X=as.data.frame(X)
colnames(X)=c('cos1', 'cos2','cos3', 'cos4', 'cos5',
'cos6', 'sin1', 'sin2', 'sin3', 'sin4',
'sin5')
reglin=lm(nottem ~ cos1 + sin1 + cos2 + sin2
+ cos3 + sin3 +cos4 + sin4 + cos5 + sin5
+cos6, data = X)
summary(reglin)
#4
reglin=lm(nottem ~ cos1 + sin1 + sin2 + sin4,
data = X)
summary(reglin)
#5
ajust=reglin$fitted.values
resid=reglin$residuals
resid=ts(resid, start=c(1920,1),
end=c(1939,12), frequency=12)
ajust=ts(ajust, start=c(1920,1),
end=c(1939,12), frequency=12)
#6
graph=cbind(nottem, ajust, resid)
plot.ts(graph)
#7 Filtrer la série de départ pour éliminer
# la saisonnalité en utilisant le filtre de
# différenciation saisonnière via la fonction
# diff. Superposer la série ainsi obtenue avec
# les résidus précédents. Commenter.
d1=diff(nottem, lag = 12)
plot.ts(d1)
lines(resid, col='red')
decompose(nottem)
plot(decompose(nottem))
require(asaur)
gastricXelox[23:27,]
head(pancreatic)
prostateSurvival[88:95,]
pharmacoSmoking[1:6,]
pharmacoSmoking[1:6,2:8]
hepatoCellular[c(1,2,3,65,71),c(2,3,16:20,24,47)]
id<-c(1,2,3,4,5)
entry<-c(1990,1990,1991,1991,1992)
end<-c(1995,1995,1995,1994,1992)
delta<-c(0,0,1,1,1)
?as.data.frame
simpledataset<-data.frame(id, entry, end, delta)
simpledataset
summary(simpledataset)
sum(simpledataset$delta)
?mutate
??mutate
require(dplyr)
install.packages("shiny")
install.packages("shinythemes")
require(DT)
require(tidyverse)
require(rAmCharts)
install.packages("rAmCharts")
install.packages("corrplot")
install.packages("plotly")
#Chargement des packages
library(dplyr)
library(sf)
library(spdep)
library(RColorBrewer)
library(leaflet)
###Import des données
#Données carroyées pour la ville de Bordeaux
bordeaux <- st_read("/Users/mathi/Documents/Ensai/2A/S2/Introduction à la statistique spatiale/Donnees/bordeaux.gpkg")
#Récupération du fond de communes et filtrage pour extraire les données relatives à Bordeaux
fond_communes <- st_read("C:/Users/mathi/Documents/Ensai/2A/S2/Introduction à la statistique spatiale/Donnees/commune_francemetro_2021/commune_francemetro_2021.shp"
, options = "ENCODING=UTF8")
fond_communes_bordeaux <- fond_communes %>%
filter(libelle=="Bordeaux")
plot(st_geometry(bordeaux))
plot(st_geometry(fond_communes_bordeaux), add=TRUE)
plot(bordeaux["part_Men_pauv"], add=TRUE)
bordeaux
colnames(bordeaux)
# création de la variable
bordeaux$part_Men_pauv <-bordeaux$Men_pauv/bordeaux$Men
bordeaux$part_Men_pauv
colnames(bordeaux)
summary(bordeaux$part_Men_pauv)
plot(st_geometry(bordeaux))
plot(st_geometry(fond_communes_bordeaux), add=TRUE)
plot(bordeaux["part_Men_pauv"], add=TRUE)
bordeaux <- bordeaux %>%
mutate(part_Men_pauv = sample(part_Men_pauv))
bordeaux <- bordeaux %>%
mutate(part_Men_pauv = sample(part_Men_pauv))
###Création de notre environment de travail
#Installation des packages
install.packages("sf")
install.packages("spdep")
#Chargement des packages
library(dplyr)
library(sf)
library(spdep)
library(RColorBrewer)
library(leaflet)
###Import des données
#Données carroyées pour la ville de Bordeaux
bordeaux <- st_read("/Users/mathi/Documents/Ensai/2A/S2/Introduction à la statistique spatiale/Donnees/bordeaux.gpkg")
#Récupération du fond de communes et filtrage pour extraire les données relatives à Bordeaux
fond_communes <- st_read("C:/Users/mathi/Documents/Ensai/2A/S2/Introduction à la statistique spatiale/Donnees/commune_francemetro_2021/commune_francemetro_2021.shp"
, options = "ENCODING=UTF8")
fond_communes_bordeaux <- fond_communes %>%
filter(libelle=="Bordeaux")
# En reprenant la méthodologie adoptée au TP6, vous étudierez s’il existe un
# phénomène d’autocorrélation spatiale associé à la part de ménages pauvres
# création de la variable
bordeaux$part_Men_pauv <-bordeaux$Men_pauv/bordeaux$Men
bordeaux$part_Men_pauv
colnames(bordeaux)
summary(bordeaux$part_Men_pauv)
# La documentation en ligne précise que le système
# de projection est le Lambert-93 (EPSG 2154)
# 2. Vous représenterez ces données carroyées en superposant le fond de la
# commune. Les carreaux dépassent-ils les frontières communales ? Si oui, quel
# intérêt y a-t-il à cela ?
plot(st_geometry(bordeaux))
plot(st_geometry(fond_communes_bordeaux), add=TRUE)
plot(bordeaux["part_Men_pauv"], add=TRUE)
# Les carreaux dépassent la frontière communale.
# L'intersection d'un carreau et de la frontière communale pourrait ne pas
# comporter suffisamment d'individus et donc violer le secret statistique.
# La construction des carreaux répond cependant au problème du MAUP. C'est
# pourquoi on les utilise.
# 3. Vous étudierez ensuite s’il existe un phénomène d’autocorrélation spatiale. Vous utiliserez l’ensemble
# des indicateurs vus en TP, évidemment le I de Moran mais également les indicateurs d’autocorrelation
# locaux (LISA). Vous testerez pour ces derniers leur significativité. Vous discuterez également des
# résultats en fonction de la notion de voisinage.
# Comparons la distribution réelle de la variable issue de notre jeu de données
# avec une distribution aléatoire.
bordeaux <- bordeaux %>%
mutate(part_Men_pauv_sample = sample(part_Men_pauv))
install.packages("sf")
install.packages("spdep")
install.packages("spdep")
###Import des données
#Données carroyées pour la ville de Bordeaux
bordeaux <- st_read("/Users/mathi/Documents/Ensai/2A/S2/Introduction à la statistique spatiale/Donnees/bordeaux.gpkg")
#Récupération du fond de communes et filtrage pour extraire les données relatives à Bordeaux
fond_communes <- st_read("C:/Users/mathi/Documents/Ensai/2A/S2/Introduction à la statistique spatiale/Donnees/commune_francemetro_2021/commune_francemetro_2021.shp"
, options = "ENCODING=UTF8")
fond_communes_bordeaux <- fond_communes %>%
filter(libelle=="Bordeaux")
# création de la variable
bordeaux$part_Men_pauv <-bordeaux$Men_pauv/bordeaux$Men
bordeaux$part_Men_pauv
colnames(bordeaux)
summary(bordeaux$part_Men_pauv)
plot(st_geometry(bordeaux))
plot(st_geometry(fond_communes_bordeaux), add=TRUE)
plot(bordeaux["part_Men_pauv"], add=TRUE)
bordeaux <- bordeaux %>%
mutate(part_Men_pauv_sample = sample(part_Men_pauv))
# Voyons voir à quoi cela ressemble:
plot(bordeaux["part_Men_pauv"], title("Réalité"))
# Voyons voir à quoi cela ressemble:
plot(bordeaux["part_Men_pauv"], title(main="Réalité"))
# Voyons voir à quoi cela ressemble:
plot(bordeaux["part_Men_pauv"], main="Réalité")
plot(bordeaux["part_Men_pauv_sample"], main="Aléatoire")
plot(bordeaux["part_Men_pauv"],breaks = "quantile", main="Réalité quantile")
plot(bordeaux["part_Men_pauv_sample"],breaks = "quantile", main="Aléatoire quantile")
plot(bordeaux["part_Men_pauv"],breaks = "jenks", main="Réalité jenks")
plot(bordeaux["part_Men_pauv_sample"],breaks = "jenks", main="Aléatoire jenks")
install.packages("mapview")
install.packages("mapview")
library(mapview)
mapview(bordeaux,
z=c("part_Men_pauv"),
alpha.regions=0.35,
layer.name="Part_Men_pauv",
label="libelle"
)
# Nous allons étudier le phénomène grâce à une matrice de voisinage. Dans un
# premier temps, nous allons définir le voisinage par la contiguïté : deux
# carreaux sont voisins s'ils sont contigus.
voisins <- poly2nb(bordeaux) #par défaut: queen = TRUE
str(voisins)
summary(voisins)
# Nous donnons un poids à chaque carreau, égal, et en incluant les carreaux
# sans voisin.
ponderation <- nb2listw(voisins, zero.policy = TRUE)
ponderation
voisins
# Nous donnons un poids à chaque carreau, égal, et en incluant les carreaux
# sans voisin.
ponderation <- nb2listw(voisins, zero.policy = TRUE)
# Nous donnons un poids à chaque carreau, égal, et en incluant les carreaux
# sans voisin.
ponderation <- nb2listw(voisins, zero.policy = TRUE)
ponderation
# Nous allons étudier le phénomène grâce à une matrice de voisinage. Dans un
# premier temps, nous allons définir le voisinage par la contiguïté : deux
# carreaux sont voisins s'ils sont contigus.
voisins <- poly2nb(bordeaux) #par défaut: queen = TRUE
str(voisins)
summary(voisins)
# Nous donnons un poids à chaque carreau, égal, et en incluant les carreaux
# sans voisin.
ponderation <- nb2listw(voisins, zero.policy = TRUE)
ponderation
str(ponderation, max.level = 1)
summary(ponderation) #zero.policy=TRUE
# Nous donnons un poids à chaque carreau, égal, et en incluant les carreaux
# sans voisin.
ponderation <- nb2listw(voisins, zero.policy = TRUE)
str(ponderation, max.level = 1)
summary(str(ponderation, max.level = 1)) #zero.policy=TRUE
str(ponderation, max.level = 1)
# On vérifie que la somme des poids est égale à 1
all(sapply(ponderation$weights, sum) == 1)
# On vérifie que la somme des poids est égale à 1
all(sapply(ponderation$weights, sum) == 1.0)
bordeaux <- st_read("/Users/mathi/Documents/Ensai/2A/S2/Introduction à la statistique spatiale/Donnees/bordeaux.gpkg")
#Récupération du fond de communes et filtrage pour extraire les données relatives à Bordeaux
fond_communes <- st_read("C:/Users/mathi/Documents/Ensai/2A/S2/Introduction à la statistique spatiale/Donnees/commune_francemetro_2021/commune_francemetro_2021.shp"
, options = "ENCODING=UTF8")
fond_communes_bordeaux <- fond_communes %>%
filter(libelle=="Bordeaux")
# En reprenant la méthodologie adoptée au TP6, vous étudierez s’il existe un
# phénomène d’autocorrélation spatiale associé à la part de ménages pauvres
# création de la variable
bordeaux$part_Men_pauv <-bordeaux$Men_pauv/bordeaux$Men
bordeaux$part_Men_pauv
colnames(bordeaux)
summary(bordeaux$part_Men_pauv)
# La documentation en ligne précise que le système
# de projection est le Lambert-93 (EPSG 2154)
# 2. Vous représenterez ces données carroyées en superposant le fond de la
# commune. Les carreaux dépassent-ils les frontières communales ? Si oui, quel
# intérêt y a-t-il à cela ?
plot(st_geometry(bordeaux))
plot(st_geometry(fond_communes_bordeaux), add=TRUE)
plot(bordeaux["part_Men_pauv"], add=TRUE)
# Les carreaux dépassent la frontière communale.
# L'intersection d'un carreau et de la frontière communale pourrait ne pas
# comporter suffisamment d'individus et donc violer le secret statistique.
# La construction des carreaux répond cependant au problème du MAUP. C'est
# pourquoi on les utilise.
# 3. Vous étudierez ensuite s’il existe un phénomène d’autocorrélation spatiale. Vous utiliserez l’ensemble
# des indicateurs vus en TP, évidemment le I de Moran mais également les indicateurs d’autocorrelation
# locaux (LISA). Vous testerez pour ces derniers leur significativité. Vous discuterez également des
# résultats en fonction de la notion de voisinage.
# Comparons la distribution réelle de la variable issue de notre jeu de données
# avec une distribution aléatoire.
bordeaux <- bordeaux %>%
mutate(part_Men_pauv_sample = sample(part_Men_pauv))
# Voyons voir à quoi cela ressemble:
plot(bordeaux["part_Men_pauv"], main="Réalité")
plot(bordeaux["part_Men_pauv_sample"], main="Aléatoire")
# Clairement, la réalité semble présenter un phénomène d'autocorrélation
# spatiale positive. Les voisins ont tendance à prendre des valeurs similaires.
# On peut vérifier avec les méthodes quantile et jenks
plot(bordeaux["part_Men_pauv"],breaks = "quantile", main="Réalité quantile")
plot(bordeaux["part_Men_pauv_sample"],breaks = "quantile", main="Aléatoire quantile")
plot(bordeaux["part_Men_pauv"],breaks = "jenks", main="Réalité jenks")
plot(bordeaux["part_Men_pauv_sample"],breaks = "jenks", main="Aléatoire jenks")
# même constat...
#Pour se donner une meilleure idée, on regarde sur un fonds de carte
# OpenstreetMap.
# install.packages("mapview")
library(mapview)
mapview(bordeaux,
z=c("part_Men_pauv"),
alpha.regions=0.35,
layer.name="Part_Men_pauv",
label="libelle"
)
# On observe que les carreaux ayant la part des ménages pauvres la plus élevée
# se concentrent autour du quartier de la gare, ainsi que sur la rive droite qui
# est une zone plus récente avec de nombreuses tours. A l'inverse, l'ouest est
# constitués d'une plus faible part de ménages pauvres. Il s'agit de quartiers
# plus résidentiels composés principalement d'"échoppes bordelaises".
# Nous allons étudier le phénomène grâce à une matrice de voisinage. Dans un
# premier temps, nous allons définir le voisinage par la contiguïté : deux
# carreaux sont voisins s'ils sont contigus.
voisins <- poly2nb(bordeaux) #par défaut: queen = TRUE
str(voisins)
summary(voisins)
# Nous pouvons constater par exemple le nombre de carreaux selon le nombre de
# voisins.
# 0   1   2   3   4   5   6   7   8
# 12  17  29  55  36  66  84 108 351
# Nous donnons un poids à chaque carreau, égal, et en incluant les carreaux
# sans voisin.
ponderation <- nb2listw(voisins, zero.policy = TRUE)
str(ponderation, max.level = 1)
summary(str(ponderation, max.level = 1)) #zero.policy=TRUE
# On vérifie que la somme des poids est égale à 1
all(sapply(ponderation$weights, sum) == 1
)
str(ponderation$weights)
# Nous donnons un poids à chaque carreau, égal, et en incluant les carreaux
# sans voisin.
ponderation <- nb2listw(voisins, zero.policy = FALSE)
str(ponderation, max.level = 1)
summary(str(ponderation, max.level = 1)) #zero.policy=TRUE
# On vérifie que la somme des poids est égale à 1
all(sapply(ponderation$weights, sum) == 1)
# diagramme de Moran, avec une standardisation de la variable.
bordeaux <- bordeaux %>%
mutate(part_Men_pauv_standardise = scale(part_Men_pauv))
mean(bordeaux$part_Men_pauv_standardise)
sd(bordeaux$part_Men_pauv_standardise)
# On a bien une moyenne proche de 0 et une variance égale à 1.
moran.plot(
as.numeric(bordeaux$part_Men_pauv_standardise),
listw = ponderation,
xlab = "Part des ménages pauvres par carreau",
ylab = "Moyenne de la part des ménages pauvres des voisins",
main = "Diagramme de Moran"
)
# On réalise une mesure globale du phénomène à travers le I de Moran.
moran.test(bordeaux$part_Men_pauv_standardise
, ponderation
, randomisation = TRUE
, zero.policy = TRUE)
# Etude des LISA
# Rappel:Pour chaque observation, ils indiquent l'intensité du regroupement
# de valeurs similaires (ou de tendances opposées) autour de cette observation.
lisa_bordeaux_lisa <- spdep::localmoran(bordeaux$part_Men_pauv
, ponderation, zero.policy = TRUE)
# Etude des LISA
# Rappel:Pour chaque observation, ils indiquent l'intensité du regroupement
# de valeurs similaires (ou de tendances opposées) autour de cette observation.
lisa_bordeaux <- spdep::localmoran(bordeaux$part_Men_pauv
, ponderation, zero.policy = TRUE)
class(lisa_bordeaux)
str(lisa_bordeaux, max.level = 1)
summary(lisa_bordeaux)
mean(lisa_bordeaux[,1])
# On remarque que la moyenne de Lisa est égale au I de Moran global. En effet,
# les Lisa sont construits de telle sorte que leur somme soit proportionnelle
# au I de Moran global.
table(lisa_bordeaux[,"Ii"] < 0)
# On remarque que la moyenne de Lisa est égale au I de Moran global. En effet,
# les Lisa sont construits de telle sorte que leur somme soit proportionnelle
# au I de Moran global.
table(lisa_bordeaux[,"Ii"] > 0)
# On remarque que la moyenne de Lisa est égale au I de Moran global. En effet,
# les Lisa sont construits de telle sorte que leur somme soit proportionnelle
# au I de Moran global.
table(lisa_bordeaux[,"Ii"] >= 0)
#Visualisation
plot(bordeaux["lisa"]
, breaks = c(-8.5,-1.2,-0.7,-0.1,0,0.1,0.7,1.2,8.5)
, pal = pal)
# Représentons les LISA sur la carte:
bordeaux <- bordeaux %>%
mutate(lisa = lisa_bordeaux[,"Ii"])
#Spécification de la palette
pal <- rev(RColorBrewer::brewer.pal(8, "RdYlBu"))
#Visualisation
plot(bordeaux["lisa"]
, breaks = c(-8.5,-1.2,-0.7,-0.1,0,0.1,0.7,1.2,8.5)
, pal = pal)
# Il faut néanmoins savoir si les Lisa calculés sont significativement
# différents de zéro
bordeaux <- bordeaux %>%
mutate(lisa_p_value = lisa_bordeaux[,5])
# On se place à un niveau de confiance de 95%
table(bordeaux$lisa_p_value < 0.05)
summary(bordeaux$lisa_p_value)
lisa_bordeaux
head(lisa_bordeaux)
# On se place à un niveau de confiance de 95%
table(bordeaux$lisa_p_value < 0.05)
summary(bordeaux$lisa_p_value)
# Nous constatons que 249 carreaux ont un lisa significativement différent de
# 0 au seuil de 5%.
# Visualisation des p_values.
plot(bordeaux["lisa_p_value"], breaks = c(0, 0.01, 0.05, 0.1,1))
#Bonferroni
p_value_Bonferroni<-p.adjust(bordeaux$lisa_p_value, method = 'bonferroni')
summary(p_value_Bonferroni)
bordeaux <- bordeaux %>%
mutate(lisa_p_value_Bonferroni = p_value_Bonferroni)
plot(bordeaux["lisa_p_value_Bonferroni"], breaks = c(0,0.01,0.05,0.1,1))
#méthode de Holm
p_value_Holm<-p.adjust(bordeaux$lisa_p_value, method = 'holm')
summary(p_value_Holm)
bordeaux <- bordeaux %>%
mutate(lisa_p_value_Holm = p_value_Holm)
plot(bordeaux["lisa_p_value_Holm"], breaks = c(0,0.01,0.05,0.1,1))
setwd("~/Ensai/2A/S2/Introduction à la statistique spatiale/DM-Stat-Spatiale")
knitr::opts_chunk$set(echo = TRUE)
moran.plot(
as.numeric(bordeaux$part_Men_pauv_standardise),
listw = ponderation,
xlab = "Part des ménages pauvres par carreau",
ylab = "Moyenne de la part des ménages pauvres des voisins",
main = "Diagramme de Moran"
)
